---
title: "Grounding Inferred Relationships in Complex World Models with Continual Reasoning" 
date: 2025-02-12
lastmod: 2025-03-12
tags: ["Continual Learning","Complex World Model","External Representation","Deep Causal Relationships", "Scientific Discovery"]
author: ["Diksha Shrivastava", "Mann Acharya", "Dr. Tapas Badal"]
description: "" 
summary: "This paper proposes a Continual Reasoning framework to improve language models' ability to infer relationships in complex world models like ARC-AGI and DABStep. By leveraging a structured external memory for hypothesis generation and refinement, our approach allows models to iteratively learn relationships at inference time, enhancing their adaptability to out-of-distribution tasks." 
cover:
    image: "paper1.png"
    relative: false
editPost:
    URL: https://github.com/Entangled-Causality
    Text: "Work in Progress"

---

##### Preliminary Abstract

Language models struggle to infer and reason about implicit relationships in complex world models, significantly limiting
their decision-making capabilities. Benchmarks like ARC-AGI and DABStep illustrate these challenges, where state-of-the-art
models achieve only 55% and 16.4% accuracy, respectively. We propose a Continual Reasoning framework to ground inferred
relationships at inference time, enabling models to learn premises dynamically without a predefined domain-specific language.
Our approach utilizes an external memory structured as a dynamic hypothesis graph, allowing iterative refinement of 
relationships through interaction. We hypothesize that defining entity containers within a structured memory can optimize 
the hypothesis search space, making inference in complex world models more efficient. This work aims to enhance AI-driven 
scientific discovery and decision-making in real-world, data-driven environments.
